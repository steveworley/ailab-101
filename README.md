# AI Lab 101 â€” FGSM

This is a simple implementation of the Fast Gradient Sign Method (FGSM) attack on the MNIST dataset. The MNIST dataset is a collection of handwritten digits and is a common dataset for testing and training machine learning models. The goal of this lab is to understand the concept of adversarial attacks and to implement the Fast Gradient Sign Method (FGSM) attack.

## Objectives

- Understand the concept of adversarial attacks
- Implement the Fast Gradient Sign Method (FGSM)

## Setup

```bash
python -m venv ai-lab-101
source ai-lab-101/bin/activate
pip install -r requirements.txt
```

## Usage

```bash
python main.py
```

```bash
python resillience.py
```

